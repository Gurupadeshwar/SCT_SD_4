import requests
from bs4 import BeautifulSoup
import csv

def get_search_url(query):
    base = "https://www.flipkart.com/search?q="
    return base + query.replace(" ", "+")

def extract_product_info(soup):
    products = []
    cards = soup.find_all("div", {"class": "_1AtVbE"})

    for card in cards:
        name = card.find("div", {"class": "_4rR01T"})  # For laptops/phones
        if not name:
            name = card.find("a", {"class": "s1Q9rs"})  # For fashion items

        price = card.find("div", {"class": "_30jeq3 _1_WHN1"})
        rating = card.find("div", {"class": "_3LWZlK"})

        if name and price:
            products.append({
                "Product Name": name.text.strip(),
                "Price": price.text.strip(),
                "Rating": rating.text.strip() if rating else "No Rating"
            })
    return products

def save_to_csv(data, filename="products.csv"):
    with open(filename, mode="w", newline="", encoding="utf-8") as file:
        writer = csv.DictWriter(file, fieldnames=["Product Name", "Price", "Rating"])
        writer.writeheader()
        writer.writerows(data)
    print(f"\n‚úÖ Saved {len(data)} products to {filename}")

def main():
    print("üîç Product Info Extractor - Flipkart")
    query = input("Enter product name to search: ").strip()

    if not query:
        print("‚ùå Please enter a valid search keyword.")
        return

    url = get_search_url(query)
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print("‚ùå Failed to retrieve data. Try again later.")
        return

    soup = BeautifulSoup(response.content, "html.parser")
    products = extract_product_info(soup)

    if not products:
        print("‚ö†Ô∏è No products found.")
    else:
        save_to_csv(products)

if __name__ == "__main__":
    main()
